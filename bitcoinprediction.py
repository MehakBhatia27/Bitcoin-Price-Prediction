# -*- coding: utf-8 -*-
"""Bitcoinprediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UgLFNIMcZmS2s2bLlzddUDpWA2Rdgcxi
"""

from google.colab import drive

drive.mount('/content/drive')

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

data = pd.read_csv('/content/drive/MyDrive/BTC-USD.csv')

prices = data['Open'].values.reshape(-1, 1)

data.head()

scaler = MinMaxScaler()
prices_scaled = scaler.fit_transform(prices)

def create_sequences(data, sequence_length):
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i : i + sequence_length])
        y.append(data[i + sequence_length])
    return np.array(X), np.array(y)

sequence_length = 100  # You can adjust this parameter
X, y = create_sequences(prices_scaled, sequence_length)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = Sequential()
model.add(LSTM(100, activation='relu', input_shape=(sequence_length, 1), return_sequences=True))

model.add(LSTM(100, activation='relu'))

model.add(Dense(1))

import tensorflow as tf
from tensorflow.keras.layers import Layer

class AlphaLeakyComponent(Layer):
    def __init__(self, alpha=0.01, **kwargs):
        super(AlphaLeakyComponent, self).__init__(**kwargs)
        self.alpha = alpha

    def call(self, inputs):
        return tf.maximum(self.alpha * inputs, inputs)

    def get_config(self):
        config = super(AlphaLeakyComponent, self).get_config()
        config.update({'alpha': self.alpha})
        return config


model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 1), return_sequences=True))
model.add(AlphaLeakyComponent(alpha=0.05))
model.add(LSTM(100, activation='relu'))
model.add(AlphaLeakyComponent(alpha=0.05))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=100, batch_size= 64, validation_data=(X_test, y_test))

# Make predictions
predicted_scaled = model.predict(X_test)
predicted = scaler.inverse_transform(predicted_scaled)

rmse = np.sqrt(np.mean(np.square(y_test - predicted)))

print(f'Root Mean Squared Error: {rmse}')

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(data['Date'][-len(y_test):], prices[-len(y_test):], label='True Prices')
plt.plot(data['Date'][-len(y_test):], predicted, label='Predicted Prices')
plt.xlabel('Date')
plt.ylabel('Bitcoin Price')
plt.title('Bitcoin Future Price Prediction')
plt.legend()
plt.show()

def calculate_accuracy(y_true, y_pred, tolerance):

    accurate_predictions = np.abs(y_true - y_pred) <= tolerance
    accuracy = np.mean(accurate_predictions) * 100.0
    return accuracy

tolerance = 0.755
accuracy = calculate_accuracy(y_test, predicted, tolerance)

print(f'Accuracy : {tolerance :.2%} ')

for i, advice in enumerate(invest_advice):
    print(f"Sample {i+1}: Invest - {advice}")

//Till Here

data = data.drop(['Adj Close'] , axis = 1)

data = data.drop(['Date'] , axis = 1)

feature = data.drop('High', axis = 1)
target = data['High']

X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.2, random_state= 45)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = Sequential()
model.add(GRU(128, activation='relu', input_shape= (X_train_scaled.shape[1], 1), return_sequences=True))
model.add(Dropout(0.2))
model.add(GRU(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='relu'))

model.add(GRU(units=64, activation='relu', return_sequences=True))
model.add(GRU(units=64, activation='relu', return_sequences=True))
model.add(GRU(units=64, activation='relu', return_sequences=True))
model.add(GRU(units=64, activation='relu', return_sequences=True))

model.add(Dense(units=1, activation='sigmoid'))

learning_rate = 0.001
adam_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(X_train,  y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

# Make predictions on new data
predictions = model.predict(X_new_data)
binary_predictions = (predictions > 0.5).astype(int)

X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)
X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

from tensorflow.keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(patience=5, restore_best_weights=True)
model.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.5, callbacks=[early_stopping])

loss, accuracy = model.evaluate(X_test_reshaped, y_test)
print(f"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}")

model = Sequential()
model.add(GRU(128, activation='sigmoid', input_shape=(X_train_scaled.shape[1], 1), return_sequences=True))
model.add(Dropout(0.2))
model.add(GRU(64, activation='sigmoid', return_sequences=True))
model.add(Dropout(0.2))
model.add(GRU(32, activation='sigmoid'))
model.add(Dense(16, activation='sigmoid'))
model.add(Dense(1, activation='sigmoid'))
learning_rate = 0.001
adam_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])
X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)
X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)
from tensorflow.keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(patience=5, restore_best_weights=True)
model.fit(X_train_reshaped, y_train, epochs=50, batch_size=64, validation_split=0.5, callbacks=[early_stopping])

loss, accuracy = model.evaluate(X_test_reshaped, y_test)
print(f"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}")

predictions = model.predict(X_test_reshaped)
binary_predictions = [1 if p > 0.9 else 0 for p in predictions ]

invest_advice = ['yes' if p == 1 else 'no' for p in binary_predictions]

predictions = model.predict(X_test_reshaped)
mse = np.mean((predictions - y_test.values.reshape(-1, 1)) ** 2)
print (mse);

for i, advice in enumerate(invest_advice):
    print(f"Sample {i+1}: Invest - {advice}")